{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc82c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_array, check_X_y\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3673d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/sumiran/Downloads/preprocessed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b91e9977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R1-PM1:V</th>\n",
       "      <th>R1-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R1-PM3:V</th>\n",
       "      <th>R1-PA4:IH</th>\n",
       "      <th>R1-PM4:I</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>...</th>\n",
       "      <th>R4-PA3:VH_R4-PA6:IH_ratio</th>\n",
       "      <th>R4-PM3:V_R4-PM6:I_ratio</th>\n",
       "      <th>R4-PA7:VH_R4-PA10:IH_ratio</th>\n",
       "      <th>R4-PM7:V_R4-PM10:I_ratio</th>\n",
       "      <th>R4-PA8:VH_R4-PA11:IH_ratio</th>\n",
       "      <th>R4-PM8:V_R4-PM11:I_ratio</th>\n",
       "      <th>R4-PA9:VH_R4-PA12:IH_ratio</th>\n",
       "      <th>R4-PM9:V_R4-PM12:I_ratio</th>\n",
       "      <th>phase_angle_diff</th>\n",
       "      <th>marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875206</td>\n",
       "      <td>-0.416331</td>\n",
       "      <td>-0.445278</td>\n",
       "      <td>-0.848774</td>\n",
       "      <td>-1.717388</td>\n",
       "      <td>-1.050588</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.991478</td>\n",
       "      <td>-0.508920</td>\n",
       "      <td>1.307889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991955</td>\n",
       "      <td>-1.072212</td>\n",
       "      <td>1.044118</td>\n",
       "      <td>-0.709692</td>\n",
       "      <td>-0.011228</td>\n",
       "      <td>-0.227103</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>-0.209933</td>\n",
       "      <td>1.320483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878600</td>\n",
       "      <td>-0.327157</td>\n",
       "      <td>-0.442027</td>\n",
       "      <td>-0.635233</td>\n",
       "      <td>-1.713841</td>\n",
       "      <td>-0.841586</td>\n",
       "      <td>0.843329</td>\n",
       "      <td>0.983953</td>\n",
       "      <td>-0.504557</td>\n",
       "      <td>1.286343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991003</td>\n",
       "      <td>-0.871280</td>\n",
       "      <td>1.044153</td>\n",
       "      <td>-0.592302</td>\n",
       "      <td>-0.011124</td>\n",
       "      <td>-0.281077</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>-0.260892</td>\n",
       "      <td>1.320628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883164</td>\n",
       "      <td>-0.165022</td>\n",
       "      <td>-0.437676</td>\n",
       "      <td>-0.246977</td>\n",
       "      <td>-1.709189</td>\n",
       "      <td>-0.461583</td>\n",
       "      <td>0.842996</td>\n",
       "      <td>1.000883</td>\n",
       "      <td>-0.500668</td>\n",
       "      <td>1.269106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>-0.523860</td>\n",
       "      <td>1.048743</td>\n",
       "      <td>-0.368436</td>\n",
       "      <td>-0.011113</td>\n",
       "      <td>-0.589095</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>-0.559892</td>\n",
       "      <td>1.320841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883109</td>\n",
       "      <td>-0.173129</td>\n",
       "      <td>-0.437834</td>\n",
       "      <td>-0.266390</td>\n",
       "      <td>-1.709363</td>\n",
       "      <td>-0.480583</td>\n",
       "      <td>0.839722</td>\n",
       "      <td>1.021575</td>\n",
       "      <td>-0.502192</td>\n",
       "      <td>1.273415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985039</td>\n",
       "      <td>-0.545961</td>\n",
       "      <td>1.051805</td>\n",
       "      <td>-0.373285</td>\n",
       "      <td>-0.011152</td>\n",
       "      <td>-1.173761</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>-1.493546</td>\n",
       "      <td>1.320942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882997</td>\n",
       "      <td>-0.189343</td>\n",
       "      <td>-0.437991</td>\n",
       "      <td>-0.285802</td>\n",
       "      <td>-1.709479</td>\n",
       "      <td>-0.518584</td>\n",
       "      <td>0.838668</td>\n",
       "      <td>1.027219</td>\n",
       "      <td>-0.502245</td>\n",
       "      <td>1.271261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984513</td>\n",
       "      <td>-0.540093</td>\n",
       "      <td>1.052372</td>\n",
       "      <td>-0.381995</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>-1.946509</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>-1.493546</td>\n",
       "      <td>1.320988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1042 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R1-PA1:VH  R1-PM1:V  R1-PA2:VH  R1-PM2:V  R1-PA3:VH  R1-PM3:V  R1-PA4:IH  \\\n",
       "0   0.875206 -0.416331  -0.445278 -0.848774  -1.717388 -1.050588   0.840000   \n",
       "1   0.878600 -0.327157  -0.442027 -0.635233  -1.713841 -0.841586   0.843329   \n",
       "2   0.883164 -0.165022  -0.437676 -0.246977  -1.709189 -0.461583   0.842996   \n",
       "3   0.883109 -0.173129  -0.437834 -0.266390  -1.709363 -0.480583   0.839722   \n",
       "4   0.882997 -0.189343  -0.437991 -0.285802  -1.709479 -0.518584   0.838668   \n",
       "\n",
       "   R1-PM4:I  R1-PA5:IH  R1-PM5:I  ...  R4-PA3:VH_R4-PA6:IH_ratio  \\\n",
       "0  0.991478  -0.508920  1.307889  ...                   0.991955   \n",
       "1  0.983953  -0.504557  1.286343  ...                   0.991003   \n",
       "2  1.000883  -0.500668  1.269106  ...                   0.987086   \n",
       "3  1.021575  -0.502192  1.273415  ...                   0.985039   \n",
       "4  1.027219  -0.502245  1.271261  ...                   0.984513   \n",
       "\n",
       "   R4-PM3:V_R4-PM6:I_ratio  R4-PA7:VH_R4-PA10:IH_ratio  \\\n",
       "0                -1.072212                    1.044118   \n",
       "1                -0.871280                    1.044153   \n",
       "2                -0.523860                    1.048743   \n",
       "3                -0.545961                    1.051805   \n",
       "4                -0.540093                    1.052372   \n",
       "\n",
       "   R4-PM7:V_R4-PM10:I_ratio  R4-PA8:VH_R4-PA11:IH_ratio  \\\n",
       "0                 -0.709692                   -0.011228   \n",
       "1                 -0.592302                   -0.011124   \n",
       "2                 -0.368436                   -0.011113   \n",
       "3                 -0.373285                   -0.011152   \n",
       "4                 -0.381995                   -0.011017   \n",
       "\n",
       "   R4-PM8:V_R4-PM11:I_ratio  R4-PA9:VH_R4-PA12:IH_ratio  \\\n",
       "0                 -0.227103                    0.013165   \n",
       "1                 -0.281077                    0.012998   \n",
       "2                 -0.589095                    0.012451   \n",
       "3                 -1.173761                    0.012782   \n",
       "4                 -1.946509                    0.012528   \n",
       "\n",
       "   R4-PM9:V_R4-PM12:I_ratio  phase_angle_diff  marker  \n",
       "0                 -0.209933          1.320483       1  \n",
       "1                 -0.260892          1.320628       1  \n",
       "2                 -0.559892          1.320841       1  \n",
       "3                 -1.493546          1.320942       1  \n",
       "4                 -1.493546          1.320988       1  \n",
       "\n",
       "[5 rows x 1042 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a6164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "# # Replacing infinite values with NaNs\n",
    "# data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data = data[~(data.isna().any(axis=1) | data.isin([np.inf, -np.inf]).any(axis=1))]\n",
    "\n",
    "# handling missing values by filling with the mean of the column\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7fe6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all columns used for scaling are numeric\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "data_scaled = scaler.fit_transform(data[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0823f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['marker'] = label_encoder.fit_transform(data.iloc[:, -1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data['marker'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays of floats\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "y_test = np.array(y_test, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6018de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DBN using RBMs\n",
    "class DBN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, rbm_layers=[256, 128], rbm_iter=10, rbm_learning_rate=0.1):\n",
    "        self.rbm_layers = rbm_layers\n",
    "        self.rbm_iter = rbm_iter\n",
    "        self.rbm_learning_rate = rbm_learning_rate\n",
    "        self.rbms = []\n",
    "        self.n_layers = len(rbm_layers)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        input_data = X\n",
    "        for i in range(self.n_layers):\n",
    "            rbm = BernoulliRBM(n_components=self.rbm_layers[i], n_iter=self.rbm_iter, learning_rate=self.rbm_learning_rate, verbose=True)\n",
    "            rbm.fit(input_data)\n",
    "            input_data = rbm.transform(input_data)\n",
    "            self.rbms.append(rbm)\n",
    "        self.rbm_output = input_data\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        input_data = X\n",
    "        for rbm in self.rbms:\n",
    "            input_data = rbm.transform(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0bbfaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate KELM\n",
    "class KELM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_units=1000, activation='sigmoid'):\n",
    "        self.hidden_units = hidden_units\n",
    "        self.activation = activation\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.input_weights = np.random.normal(size=(X.shape[1], self.hidden_units))\n",
    "        self.biases = np.random.normal(size=self.hidden_units)\n",
    "        H = self._activation_function(np.dot(X, self.input_weights) + self.biases)\n",
    "        self.output_weights = np.dot(np.linalg.pinv(H), y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = check_array(X)\n",
    "        H = self._activation_function(np.dot(X, self.input_weights) + self.biases)\n",
    "        return np.sign(np.dot(H, self.output_weights))\n",
    "    \n",
    "    def _activation_function(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation function: {}\".format(self.activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a51abad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the overall model combining DBN and KELM\n",
    "class DBN_KELM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, dbn_params=None, kelm_params=None):\n",
    "        self.dbn_params = dbn_params if dbn_params is not None else {}\n",
    "        self.kelm_params = kelm_params if kelm_params is not None else {}\n",
    "        self.dbn = DBN(**self.dbn_params)\n",
    "        self.kelm = KELM(**self.kelm_params)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_transformed = self.dbn.fit_transform(X, y)\n",
    "        self.kelm.fit(X_transformed, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_transformed = self.dbn.transform(X)\n",
    "        return self.kelm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317a517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fce9cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'dbn' for estimator DBN_KELM(dbn_params={'rbm_iter': 10, 'rbm_layers': [256, 128],\n                     'rbm_learning_rate': 0.1},\n         kelm_params={'activation': 'sigmoid', 'hidden_units': 1000}). Valid parameters are: ['dbn_params', 'kelm_params'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[1;32m     16\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Print the best parameters and best score\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    718\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 720\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[1;32m    722\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    724\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:229\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[1;32m    228\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[1;32m    235\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'dbn' for estimator DBN_KELM(dbn_params={'rbm_iter': 10, 'rbm_layers': [256, 128],\n                     'rbm_learning_rate': 0.1},\n         kelm_params={'activation': 'sigmoid', 'hidden_units': 1000}). Valid parameters are: ['dbn_params', 'kelm_params']."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example hyperparameter grid for KELM\n",
    "param_grid = {\n",
    "    'kelm__hidden_units': [500, 1000, 1500],\n",
    "    'kelm__activation': ['sigmoid', 'tanh', 'relu'],\n",
    "    'dbn__rbm_layers': [[256, 128], [512, 256], [128, 64]],\n",
    "    'dbn__rbm_iter': [10, 20],\n",
    "    'dbn__rbm_learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# # Define the overall model\n",
    "model = DBN_KELM(dbn_params=dbn_params, kelm_params=kelm_params)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model found\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cf6f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for DBN and KELM\n",
    "dbn_params = {'rbm_layers': [256, 128], 'rbm_iter': 10, 'rbm_learning_rate': 0.1}\n",
    "kelm_params = {'hidden_units': 1000, 'activation': 'sigmoid'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9655882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the DBN-KELM model\n",
    "model = DBN_KELM(dbn_params=dbn_params, kelm_params=kelm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241c9b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -272181.19, time = 80.99s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -594074.20, time = 90.99s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -855231.43, time = 47.00s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1128933.32, time = 49.75s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1513267.55, time = 42.60s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1710628.86, time = 54.63s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -2147061.42, time = 81.50s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -2223772.34, time = 105.55s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -2694625.38, time = 79.78s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -2806410.60, time = 44.76s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -13.47, time = 6.45s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -8.67, time = 6.35s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.35, time = 6.85s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -16.93, time = 6.38s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -65.99, time = 6.27s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.02, time = 6.63s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -10.79, time = 6.13s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -6.55, time = 7.22s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -53.90, time = 6.20s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.64, time = 6.08s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBN_KELM(dbn_params={&#x27;rbm_iter&#x27;: 10, &#x27;rbm_layers&#x27;: [256, 128],\n",
       "                     &#x27;rbm_learning_rate&#x27;: 0.1},\n",
       "         kelm_params={&#x27;activation&#x27;: &#x27;sigmoid&#x27;, &#x27;hidden_units&#x27;: 1000})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DBN_KELM</label><div class=\"sk-toggleable__content\"><pre>DBN_KELM(dbn_params={&#x27;rbm_iter&#x27;: 10, &#x27;rbm_layers&#x27;: [256, 128],\n",
       "                     &#x27;rbm_learning_rate&#x27;: 0.1},\n",
       "         kelm_params={&#x27;activation&#x27;: &#x27;sigmoid&#x27;, &#x27;hidden_units&#x27;: 1000})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DBN_KELM(dbn_params={'rbm_iter': 10, 'rbm_layers': [256, 128],\n",
       "                     'rbm_learning_rate': 0.1},\n",
       "         kelm_params={'activation': 'sigmoid', 'hidden_units': 1000})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "713e9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82251905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e698dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
